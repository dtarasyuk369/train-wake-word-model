# üéôÔ∏è Train Wake Word Model

–ü—Ä–æ–µ–∫—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è (wake word detection) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º [OpenWakeWord](https://github.com/dscripka/openWakeWord) –∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ [Piper TTS](https://github.com/rhasspy/piper).

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- ‚úÖ –û–±—É—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ª—é–±–æ–≥–æ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã
- ‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å TTS
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (—à—É–º, —Ä–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏—è)
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Google Colab (–±–µ—Å–ø–ª–∞—Ç–Ω–æ–µ GPU –æ–±—É—á–µ–Ω–∏–µ)
- ‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç ONNX
- ‚úÖ –ù–∏–∑–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ—Å—É—Ä—Å–∞–º –¥–ª—è inference

## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

- Python 3.8+
- NVIDIA GPU —Å CUDA (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è, –Ω–æ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
- 10+ –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
- 8+ –ì–ë RAM

### Google Colab

- –ê–∫–∫–∞—É–Ω—Ç Google
- –°—Ç–∞–±–∏–ª—å–Ω–æ–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
- ~2-8 —á–∞—Å–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

## üõ†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –í–∞—Ä–∏–∞–Ω—Ç 1: Google Colab (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö)

1. –û—Ç–∫—Ä–æ–π—Ç–µ –Ω–æ—É—Ç–±—É–∫ `colab_train.ipynb` –≤ [Google Colab](https://colab.research.google.com/)
2. –°–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –≤ –Ω–æ—É—Ç–±—É–∫–µ
3. –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: [COLAB_INSTRUCTIONS.md](COLAB_INSTRUCTIONS.md)

### –í–∞—Ä–∏–∞–Ω—Ç 2: –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone https://github.com/YOUR_USERNAME/train-wake-word-model.git
cd train-wake-word-model

# –°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏
venv\Scripts\activate  # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ Piper Sample Generator (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ TTS)
git clone https://github.com/rhasspy/piper-sample-generator.git
cd piper-sample-generator
pip install -e .
cd ..
```

## üìö –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –°–∫–∞—á–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ

```bash
# –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (MIT RIRs + AudioSet)
python download_data.py

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –¥–æ–±–∞–≤–∏—Ç—å –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Ñ–æ–Ω (~7 –ì–ë)
python download_data.py --include-fma --fma-hours 2
```

### 2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `config/default.yaml`:

```yaml
model_name: "my_wake_word"

target_phrase:
  - "hey assistant"  # –í–∞—à–µ –ø—Ä–æ–±—É–∂–¥–∞—é—â–µ–µ —Å–ª–æ–≤–æ

n_samples: 5000  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
steps: 10000     # –®–∞–≥–∏ –æ–±—É—á–µ–Ω–∏—è
```

### 3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å

```bash
# –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è ‚Üí –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è ‚Üí –æ–±—É—á–µ–Ω–∏–µ)
python train.py \
  --training_config config/default.yaml \
  --generate_clips \
  --augment_clips \
  --train_model
```

–ò–ª–∏ –ø–æ—à–∞–≥–æ–≤–æ:

```bash
# –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
python train.py --training_config config/default.yaml --generate_clips

# –®–∞–≥ 2: –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
python train.py --training_config config/default.yaml --augment_clips

# –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
python train.py --training_config config/default.yaml --train_model
```

### 4. –ü–æ–ª—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å

–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤:
```
./my_custom_model/your_model_name.onnx
```

## üìñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### Python

```python
from openwakeword.model import Model
import pyaudio
import numpy as np

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
owwModel = Model(wakeword_models=["./my_custom_model/my_wake_word.onnx"])

# –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1280

audio = pyaudio.PyAudio()
mic_stream = audio.open(
    format=FORMAT,
    channels=CHANNELS,
    rate=RATE,
    input=True,
    frames_per_buffer=CHUNK
)

# –°–ª—É—à–∞—Ç—å –∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
print("Listening for wake word...")
while True:
    audio_data = np.frombuffer(mic_stream.read(CHUNK), dtype=np.int16)
    prediction = owwModel.predict(audio_data)

    for mdl_name, score in prediction.items():
        if score > 0.5:
            print(f"‚úÖ Wake word detected! Score: {score:.2f}")
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

```python
import openwakeword
from openwakeword.model import Model

class WakeWordDetector:
    def __init__(self, model_path, threshold=0.5):
        self.model = Model(wakeword_models=[model_path])
        self.threshold = threshold

    def detect(self, audio_chunk):
        """
        audio_chunk: numpy array (1280 samples @ 16kHz = 80ms)
        Returns: True if wake word detected
        """
        predictions = self.model.predict(audio_chunk)
        return any(score > self.threshold for score in predictions.values())

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
detector = WakeWordDetector("./my_custom_model/my_wake_word.onnx")
# ... –ø–æ–ª—É—á–∏—Ç—å audio_chunk –∏–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
if detector.detect(audio_chunk):
    print("Wake word detected!")
```

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è |
|----------|----------|------------------------|
| `n_samples` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ | 3000-10000 |
| `n_samples_val` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ | 1000-5000 |
| `steps` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è | 5000-20000 |
| `layer_size` | –†–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤ –º–æ–¥–µ–ª–∏ | 32-128 |
| `max_negative_weight` | –í–µ—Å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ | 1000-2000 |
| `target_false_positives_per_hour` | –¶–µ–ª–µ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π | 0.1-0.5 |

### –ö–æ–º–ø—Ä–æ–º–∏—Å—Å—ã

**–ë–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ —à–∞–≥–æ–≤** ‚Üí –õ—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –¥–æ–ª—å—à–µ –æ–±—É—á–µ–Ω–∏–µ

**–ë–æ–ª—å—à–µ `max_negative_weight`** ‚Üí –ú–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π, –Ω–æ –º–æ–∂–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –Ω–∞—Å—Ç–æ—è—â–∏–µ

**–ú–µ–Ω—å—à–µ `layer_size`** ‚Üí –ë—ã—Å—Ç—Ä–µ–µ inference, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–º

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
train-wake-word-model/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ default.yaml              # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ audioset_16k/             # –§–æ–Ω–æ–≤—ã–π —à—É–º
‚îÇ   ‚îú‚îÄ‚îÄ mit_rirs/                 # –ò–º–ø—É–ª—å—Å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ *.npy                     # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
‚îú‚îÄ‚îÄ my_custom_model/
‚îÇ   ‚îî‚îÄ‚îÄ your_model/
‚îÇ       ‚îú‚îÄ‚îÄ positive_train/       # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ       ‚îú‚îÄ‚îÄ negative_train/       # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ       ‚îî‚îÄ‚îÄ your_model.onnx       # –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
‚îú‚îÄ‚îÄ piper-sample-generator/       # TTS –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ download_data.sh          # –°–∫—Ä–∏–ø—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                  # –°–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏
‚îÇ   ‚îî‚îÄ‚îÄ train.sh                  # –°–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ colab_train.ipynb             # –ù–æ—É—Ç–±—É–∫ –¥–ª—è Google Colab
‚îú‚îÄ‚îÄ download_data.py              # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îú‚îÄ‚îÄ train.py                      # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ requirements.txt              # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îú‚îÄ‚îÄ COLAB_INSTRUCTIONS.md         # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è Colab
‚îî‚îÄ‚îÄ README.md                     # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üêõ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### CUDA out of memory

–£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä—ã –±–∞—Ç—á–µ–π:
```yaml
tts_batch_size: 16
augmentation_batch_size: 8
batch_n_per_class:
  ACAV100M_sample: 512
  adversarial_negative: 32
  positive: 32
```

### –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏

1. –£–≤–µ–ª–∏—á—å—Ç–µ `n_samples` (–±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤)
2. –£–≤–µ–ª–∏—á—å—Ç–µ `steps` (–¥–æ–ª—å—à–µ –æ–±—É—á–µ–Ω–∏–µ)
3. –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞
4. –£–≤–µ–ª–∏—á—å—Ç–µ `augmentation_rounds`
5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `layer_size: 64` –∏–ª–∏ `128`

### –ú–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π

–£–≤–µ–ª–∏—á—å—Ç–µ `max_negative_weight` –∏–ª–∏ `target_false_positives_per_hour: 0.1`

### –ú–æ–¥–µ–ª—å –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏

–£–º–µ–Ω—å—à–∏—Ç–µ `max_negative_weight` –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤

## üåê –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —è–∑—ã–∫–æ–≤

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫—É—é TTS –º–æ–¥–µ–ª—å. –î–ª—è –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤:

1. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å Piper –¥–ª—è –Ω—É–∂–Ω–æ–≥–æ —è–∑—ã–∫–∞: https://github.com/rhasspy/piper/releases
2. –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
```yaml
piper_model_path: "./models/ru_RU-ruslan-medium.pt"  # –ü—Ä–∏–º–µ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
```

–î–æ—Å—Ç—É–ø–Ω—ã–µ —è–∑—ã–∫–∏: –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, —Ä—É—Å—Å–∫–∏–π, –Ω–µ–º–µ—Ü–∫–∏–π, —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π, –∏—Å–ø–∞–Ω—Å–∫–∏–π, –∫–∏—Ç–∞–π—Å–∫–∏–π –∏ [–¥—Ä—É–≥–∏–µ](https://github.com/rhasspy/piper/blob/master/VOICES.md).

## üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

–¢–∏–ø–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:

- **Accuracy**: 85-95%
- **Recall**: 70-90%
- **False Positives**: 0.1-0.5 per hour
- **Latency**: ~50ms –Ω–∞ CPU, ~10ms –Ω–∞ GPU
- **Model Size**: 50-200 KB (ONNX)

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

Contributions welcome! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞:

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch (`git checkout -b feature/amazing-feature`)
3. Commit –∏–∑–º–µ–Ω–µ–Ω–∏—è (`git commit -m 'Add amazing feature'`)
4. Push –≤ branch (`git push origin feature/amazing-feature`)
5. –û—Ç–∫—Ä–æ–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ open-source –ø—Ä–æ–µ–∫—Ç—ã:

- [OpenWakeWord](https://github.com/dscripka/openWakeWord) - Apache 2.0
- [Piper TTS](https://github.com/rhasspy/piper) - MIT
- [PyTorch](https://pytorch.org/) - BSD

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- [David Scripka](https://github.com/dscripka) –∑–∞ OpenWakeWord
- [Rhasspy](https://github.com/rhasspy) –∑–∞ Piper TTS
- [AudioSet](https://research.google.com/audioset/) –∏ [MIT Acoustical Reverberation Scene Statistics Survey](https://mcdermottlab.mit.edu/Reverb/IR_Survey.html) –∑–∞ –¥–∞—Ç–∞—Å–µ—Ç—ã

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

- **Issues**: [GitHub Issues](https://github.com/YOUR_USERNAME/train-wake-word-model/issues)
- **Discussions**: [GitHub Discussions](https://github.com/YOUR_USERNAME/train-wake-word-model/discussions)
- **Email**: your.email@example.com

## üó∫Ô∏è Roadmap

- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
- [ ] Web UI –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- [ ] –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å–ª–æ–≤
- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ edge-—É—Å—Ç—Ä–æ–π—Å—Ç–≤ (Raspberry Pi, ESP32)
- [ ] Real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è
- [ ] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

---

Made with ‚ù§Ô∏è for voice interface developers
